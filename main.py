#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå¤§è°±è¡¨å…‰å­¦éŸ³ä¹è¯†åˆ«ç³»ç»Ÿ
åªåŒ…å«ï¼šYOLO11åˆ†å‰² â†’ åå¤„ç† â†’ å°ºå¯¸è°ƒæ•´
ç§»é™¤SMTè¯†åˆ«éƒ¨åˆ†ï¼Œç³»ç»Ÿæ›´ç¨³å®š
"""

import os
import sys
import argparse
import yaml
import time
from pathlib import Path
from datetime import datetime
import traceback

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

# å¯¼å…¥ç®€åŒ–ç‰ˆæ¨¡å—
from src.yolov8_predictor import YOLOv8Predictor
from src.staff_processor import StaffProcessor
from src.image_resizer import ImageResizer
from utils.file_utils import ensure_dir, clean_temp_files
from utils.visualization import visualize_detections


class SimplifiedGrandStaffOMR:
    """ç®€åŒ–ç‰ˆå¤§è°±è¡¨OMRç³»ç»Ÿï¼ˆæ— SMTè¯†åˆ«ï¼‰"""

    def __init__(self, config_path="config.yaml"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.config = self._load_config(config_path)
        self._init_paths()
        self._init_components()

        print("=" * 60)
        print("ğŸµ ç®€åŒ–ç‰ˆå¤§è°±è¡¨OMRç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("   åŠŸèƒ½: YOLO11måˆ†å‰² + åå¤„ç† + å°ºå¯¸è°ƒæ•´")
        print(f"   è®¾å¤‡: {self.config['yolo']['device']}")
        print(f"   è¾“å‡ºç›®å½•: {self.config['output']['base_dir']}")
        print("=" * 60)

    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            # åˆ›å»ºé»˜è®¤é…ç½®
            default_config = self._get_default_config()
            ensure_dir(os.path.dirname(config_path))
            with open(config_path, 'w') as f:
                yaml.dump(default_config, f, default_flow_style=False)
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºé»˜è®¤é…ç½®: {config_path}")
            return default_config

        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        # è®¾ç½®è®¾å¤‡ï¼ˆè‡ªåŠ¨æ£€æµ‹CUDAï¼‰
        import torch
        device = config['yolo']['device']
        if device == "auto":
            device = "cuda" if torch.cuda.is_available() else "cpu"
        config['yolo']['device'] = device

        return config

    def _get_default_config(self):
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'yolo': {
                'model_path': 'models/yolo11m.pt',
                'input_size': 1280,
                'conf_threshold': 0.25,
                'iou_threshold': 0.45,
                'device': 'auto'
            },
            'postprocess': {
                'target_label': 'B_u',
                'target_height': 256,
                'conf_threshold': 0.5,
                'margin': 30,
                'min_expansion': 0.05,
                'max_expansion': 0.3,
                'debug_mode': False
            },
            'output': {
                'base_dir': 'simplified_results',
                'save_intermediate': False,
                'save_visualizations': True,
                'save_cropped_staffs': True
            },
            'paths': {
                'temp_dir': 'temp',
                'intermediate_dir': 'intermediate',
                'final_output_dir': 'cropped_staffs',
                'detection_dir': 'detections'
            }
        }

    def _init_paths(self):
        """åˆå§‹åŒ–è·¯å¾„"""
        base_dir = Path(self.config['output']['base_dir'])
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        self.paths = {
            'base': base_dir / timestamp,
            'temp': base_dir / timestamp / self.config['paths']['temp_dir'],
            'intermediate': base_dir / timestamp / self.config['paths']['intermediate_dir'],
            'cropped_staffs': base_dir / timestamp / self.config['paths']['final_output_dir'],
            'detections': base_dir / timestamp / self.config['paths']['detection_dir'],
            'visualizations': base_dir / timestamp / 'visualizations'
        }

        # åˆ›å»ºæ‰€æœ‰ç›®å½•
        for path in self.paths.values():
            ensure_dir(path)

    def _init_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("ğŸ”„ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")

        try:
            # 1. YOLOåˆ†å‰²å™¨
            print("  1. åŠ è½½YOLO11måˆ†å‰²æ¨¡å‹...")
            self.yolo_predictor = YOLOv8Predictor(
                model_path=self.config['yolo']['model_path'],
                conf_threshold=self.config['yolo']['conf_threshold'],
                iou_threshold=self.config['yolo']['iou_threshold'],
                device=self.config['yolo']['device']
            )
            print(f"     âœ“ YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")

            # 2. è°±è¡¨å¤„ç†å™¨
            print("  2. åˆå§‹åŒ–è°±è¡¨åå¤„ç†å™¨...")
            self.staff_processor = StaffProcessor(
                target_label=self.config['postprocess']['target_label'],
                target_height=self.config['postprocess']['target_height'],
                conf_threshold=self.config['postprocess']['conf_threshold'],
                margin=self.config['postprocess']['margin']
            )
            print(f"     âœ“ è°±è¡¨å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

            # 3. å›¾åƒå°ºå¯¸è°ƒæ•´å™¨
            print("  3. åˆå§‹åŒ–å›¾åƒå°ºå¯¸è°ƒæ•´å™¨...")
            self.image_resizer = ImageResizer(
                target_height=self.config['postprocess']['target_height']
            )
            print(f"     âœ“ å›¾åƒå°ºå¯¸è°ƒæ•´å™¨åˆå§‹åŒ–æˆåŠŸ")

            print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            traceback.print_exc()
            sys.exit(1)

    def process_single_image(self, image_path):
        """
        å¤„ç†å•å¼ ä¹è°±å›¾åƒï¼ˆç®€åŒ–ç‰ˆï¼Œæ— SMTè¯†åˆ«ï¼‰

        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„

        Returns:
            dict: å¤„ç†ç»“æœ
        """
        print(f"\n{'=' * 60}")
        print(f"ğŸµ å¼€å§‹å¤„ç†: {image_path}")
        print(f"{'=' * 60}")

        start_time = time.time()
        image_name = Path(image_path).stem

        try:
            # 1. YOLOåˆ†å‰²
            print(f"\nğŸ” æ­¥éª¤1: YOLOå¤§è°±è¡¨åˆ†å‰²...")
            yolo_results = self.yolo_predictor.predict(image_path)

            if not yolo_results['detections']:
                print("âš ï¸  æœªæ£€æµ‹åˆ°å¤§è°±è¡¨åŒºåŸŸ")
                return {
                    'success': False,
                    'error': 'æœªæ£€æµ‹åˆ°å¤§è°±è¡¨åŒºåŸŸ',
                    'image_path': image_path
                }

            print(f"    âœ“ æ£€æµ‹åˆ° {len(yolo_results['detections'])} ä¸ªå¤§è°±è¡¨åŒºåŸŸ")

            # ä¿å­˜æ£€æµ‹ç»“æœå¯è§†åŒ–
            if self.config['output']['save_visualizations']:
                print(f"    ğŸ¨ ç”Ÿæˆæ£€æµ‹ç»“æœå¯è§†åŒ–...")
                vis_path = self.paths['detections'] / f"{image_name}_detections.png"
                self.yolo_predictor.visualize_detections(image_path, str(vis_path))
                print(f"      âœ“ å¯è§†åŒ–å·²ä¿å­˜: {vis_path}")

            # 2. è°±è¡¨åå¤„ç†
            print(f"ğŸ¯ æ­¥éª¤2: è°±è¡¨åŒºåŸŸåå¤„ç†...")
            staff_regions = self.staff_processor.process_regions(
                image_path,
                yolo_results['detections']
            )

            if not staff_regions:
                print("âš ï¸  åå¤„ç†åæ— æœ‰æ•ˆè°±è¡¨åŒºåŸŸ")
                return {
                    'success': False,
                    'error': 'åå¤„ç†åæ— æœ‰æ•ˆè°±è¡¨åŒºåŸŸ',
                    'image_path': image_path
                }

            print(f"    âœ“ åå¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(staff_regions)} ä¸ªè°±è¡¨åŒºåŸŸ")

            # 3. å°ºå¯¸è°ƒæ•´å¹¶ä¿å­˜ç»“æœ
            print(f"ğŸ“ æ­¥éª¤3: å°ºå¯¸æ ‡å‡†åŒ–...")
            cropped_results = []

            for i, region in enumerate(staff_regions):
                region_img = region['image']

                # å°ºå¯¸è°ƒæ•´
                resized_img = self.image_resizer.resize(region_img)

                # ä¿å­˜è°ƒæ•´åçš„å›¾åƒ
                if self.config['output']['save_cropped_staffs']:
                    output_filename = f"{image_name}_staff_{i:03d}.png"
                    output_path = self.paths['cropped_staffs'] / output_filename
                    self.image_resizer.save_image(resized_img, str(output_path))

                    cropped_results.append({
                        'id': i,
                        'original_bbox': region.get('original_bbox', region['bbox']),
                        'processed_bbox': region['bbox'],
                        'confidence': region['confidence'],
                        'image_path': str(output_path),
                        'image_size': resized_img.shape[:2]
                    })

                    print(f"      âœ“ ä¿å­˜è°±è¡¨ {i + 1}: {output_filename}")

            # 4. ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–ç»“æœ
            if self.config['output']['save_visualizations']:
                print(f"\nğŸ¨ æ­¥éª¤4: ç”Ÿæˆå®Œæ•´å¯è§†åŒ–ç»“æœ...")
                self._create_comprehensive_visualization(
                    image_path, yolo_results, staff_regions, image_name
                )

            # 5. ä¿å­˜å¤„ç†æŠ¥å‘Š
            print(f"ğŸ“Š æ­¥éª¤5: ç”Ÿæˆå¤„ç†æŠ¥å‘Š...")
            report_data = self._save_processing_report(
                image_name, yolo_results, staff_regions, cropped_results
            )

            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not self.config['output']['save_intermediate']:
                clean_temp_files(str(self.paths['temp']))

            print(f"\n{'=' * 60}")
            print(f"âœ… å¤„ç†å®Œæˆ!")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
            print(f"   æ£€æµ‹åŒºåŸŸ: {len(yolo_results['detections'])}ä¸ª")
            print(f"   å¤„ç†åŒºåŸŸ: {len(staff_regions)}ä¸ª")
            print(f"   è¾“å‡ºç›®å½•: {self.paths['base']}")
            print(f"{'=' * 60}")

            return {
                'success': True,
                'processing_time': processing_time,
                'detections_count': len(yolo_results['detections']),
                'processed_count': len(staff_regions),
                'cropped_count': len(cropped_results),
                'output_dir': str(self.paths['base']),
                'report': report_data
            }

        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
                'image_path': image_path
            }

    def _create_comprehensive_visualization(self, image_path, yolo_results, staff_regions, image_name):
        """åˆ›å»ºå®Œæ•´çš„å¯è§†åŒ–ç»“æœ"""
        import cv2
        import numpy as np

        # è¯»å–åŸå§‹å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            print("âš ï¸  æ— æ³•è¯»å–å›¾åƒè¿›è¡Œå¯è§†åŒ–")
            return

        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        vis_image = image.copy()

        # ç»˜åˆ¶YOLOæ£€æµ‹æ¡†ï¼ˆç»¿è‰²ï¼‰
        for detection in yolo_results['detections']:
            x1, y1, x2, y2 = detection['bbox']
            label = detection['label']
            conf = detection['confidence']

            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # æ ‡ç­¾æ–‡æœ¬
            label_text = f"{label}: {conf:.2f}"
            cv2.putText(vis_image, label_text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # ç»˜åˆ¶åå¤„ç†åŒºåŸŸï¼ˆçº¢è‰²ï¼‰
        for i, region in enumerate(staff_regions):
            x1, y1, x2, y2 = region['bbox']

            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 0, 255), 2)

            # åŒºåŸŸç¼–å·
            cv2.putText(vis_image, f"Staff {i}", (x1, y1 - 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

        # æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜
        title = f"Grand Staff Detection & Processing: {image_name}"
        cv2.putText(vis_image, title, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # æ·»åŠ å›¾ä¾‹
        legend_y = 70
        cv2.putText(vis_image, "Legend:", (10, legend_y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(vis_image, "Green: YOLO Detection", (10, legend_y + 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(vis_image, "Red: Processed Region", (10, legend_y + 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.putText(vis_image, f"Total Detections: {len(yolo_results['detections'])}",
                    (10, legend_y + 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(vis_image, f"Processed Regions: {len(staff_regions)}",
                    (10, legend_y + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        vis_path = self.paths['visualizations'] / f"{image_name}_full_visualization.png"
        cv2.imwrite(str(vis_path), vis_image)

        print(f"      âœ“ å®Œæ•´å¯è§†åŒ–å·²ä¿å­˜: {vis_path}")

        # å¦‚æœæ£€æµ‹åŒºåŸŸè¾ƒå°‘ï¼Œè¿˜å¯ä»¥åˆ›å»ºå¹¶æ’å¯¹æ¯”å›¾
        if len(staff_regions) <= 6:
            self._create_side_by_side_visualization(staff_regions, image_name)

    def _create_side_by_side_visualization(self, staff_regions, image_name):
        """åˆ›å»ºå¹¶æ’å¯¹æ¯”å¯è§†åŒ–"""
        import cv2
        import numpy as np

        # è®¡ç®—å¸ƒå±€
        n_regions = len(staff_regions)
        cols = min(3, n_regions)
        rows = (n_regions + cols - 1) // cols

        # è·å–æœ€å¤§å°ºå¯¸
        max_h, max_w = 0, 0
        for region in staff_regions:
            h, w = region['image'].shape[:2]
            max_h = max(max_h, h)
            max_w = max(max_w, w)

        # åˆ›å»ºç”»å¸ƒ
        canvas_h = rows * max_h + 50
        canvas_w = cols * max_w + 50
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255

        # ç²˜è´´æ¯ä¸ªåŒºåŸŸ
        for i, region in enumerate(staff_regions):
            row = i // cols
            col = i % cols

            img = region['image']
            h, w = img.shape[:2]

            # è®¡ç®—ä½ç½®
            x = col * max_w + 25
            y = row * max_h + 25

            # å°†å›¾åƒç²˜è´´åˆ°ç”»å¸ƒä¸Š
            canvas[y:y + h, x:x + w] = img

            # æ·»åŠ æ ‡ç­¾
            label = f"Staff {i}"
            cv2.putText(canvas, label, (x, y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

            # æ·»åŠ è¾¹ç•Œæ¡†ä¿¡æ¯
            bbox_info = f"Size: {w}x{h}"
            cv2.putText(canvas, bbox_info, (x, y + h + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

        # æ·»åŠ æ ‡é¢˜
        title = f"Cropped Staff Regions ({n_regions} total)"
        cv2.putText(canvas, title, (20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)

        # ä¿å­˜
        side_path = self.paths['visualizations'] / f"{image_name}_staff_grid.png"
        cv2.imwrite(str(side_path), canvas)

        print(f"      âœ“ å¹¶æ’å¯¹æ¯”å›¾å·²ä¿å­˜: {side_path}")

    def _save_processing_report(self, image_name, yolo_results, staff_regions, cropped_results):
        """ä¿å­˜å¤„ç†æŠ¥å‘Š"""
        import json

        report_data = {
            'image_name': image_name,
            'processing_time': datetime.now().isoformat(),
            'yolo_detections': {
                'total_count': len(yolo_results['detections']),
                'detections': yolo_results['detections']
            },
            'staff_regions': {
                'total_count': len(staff_regions),
                'regions': [
                    {
                        'id': i,
                        'bbox': region['bbox'],
                        'original_bbox': region.get('original_bbox', region['bbox']),
                        'confidence': region['confidence']
                    }
                    for i, region in enumerate(staff_regions)
                ]
            },
            'cropped_results': cropped_results,
            'output_directories': {
                'base': str(self.paths['base']),
                'cropped_staffs': str(self.paths['cropped_staffs']),
                'visualizations': str(self.paths['visualizations']),
                'detections': str(self.paths['detections'])
            }
        }

        # ä¿å­˜ä¸ºJSON
        json_path = self.paths['base'] / f"{image_name}_report.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ä¸ºTXTï¼ˆæ›´æ˜“è¯»ï¼‰
        txt_path = self.paths['base'] / f"{image_name}_report.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"Grand Staff OMR Processing Report\n")
            f.write("=" * 60 + "\n\n")

            f.write(f"Image: {image_name}\n")
            f.write(f"Processing Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write(f"YOLO Detections: {len(yolo_results['detections'])}\n")
            for i, det in enumerate(yolo_results['detections']):
                f.write(f"  {i + 1}. {det['label']}: bbox={det['bbox']}, conf={det['confidence']:.3f}\n")

            f.write(f"\nProcessed Staff Regions: {len(staff_regions)}\n")
            for i, region in enumerate(staff_regions):
                f.write(f"  {i + 1}. bbox={region['bbox']}, conf={region['confidence']:.3f}\n")

            f.write(f"\nCropped Images: {len(cropped_results)}\n")
            for result in cropped_results:
                f.write(f"  Staff {result['id']}: {result['image_path']}\n")

            f.write(f"\nOutput Directories:\n")
            for key, path in report_data['output_directories'].items():
                f.write(f"  {key}: {path}\n")

            f.write(f"\n" + "=" * 60 + "\n")
            f.write("End of Report\n")
            f.write("=" * 60 + "\n")

        print(f"      âœ“ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {txt_path}")

        return report_data

    def process_batch(self, input_dir):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒ"""
        input_dir = Path(input_dir)

        # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„å›¾åƒæ–‡ä»¶
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        image_files = []

        for ext in image_extensions:
            image_files.extend(input_dir.glob(f"*{ext}"))
            image_files.extend(input_dir.glob(f"*{ext.upper()}"))

        if not image_files:
            print(f"âŒ æœªæ‰¾åˆ°æ”¯æŒçš„å›¾åƒæ–‡ä»¶: {input_dir}")
            return []

        print(f"ğŸ“ å‘ç° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")

        # æ‰¹é‡å¤„ç†
        all_results = []
        for img_path in image_files:
            print(f"\n{'#' * 60}")
            print(f"å¤„ç†: {img_path.name}")
            print(f"{'#' * 60}")

            result = self.process_single_image(str(img_path))
            all_results.append(result)

            if result['success']:
                print(f"âœ… å¤„ç†æˆåŠŸ")
            else:
                print(f"âŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        # ç”Ÿæˆæ‰¹é‡æŠ¥å‘Š
        self._generate_batch_report(all_results)

        return all_results

    def _generate_batch_report(self, results):
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        total = len(results)
        successful = sum(1 for r in results if r.get('success', False))
        failed = total - successful

        report_path = self.paths['base'] / "batch_report.txt"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("       æ‰¹é‡å¤„ç†æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»æ–‡ä»¶æ•°: {total}\n")
            f.write(f"æˆåŠŸå¤„ç†: {successful}\n")
            f.write(f"å¤„ç†å¤±è´¥: {failed}\n")
            f.write(f"æˆåŠŸç‡: {successful / total * 100:.1f}%\n\n")

            # æ±‡æ€»ç»Ÿè®¡
            total_detections = sum(r.get('detections_count', 0) for r in results if r.get('success', False))
            total_processed = sum(r.get('processed_count', 0) for r in results if r.get('success', False))
            total_cropped = sum(r.get('cropped_count', 0) for r in results if r.get('success', False))

            f.write(f"æ±‡æ€»ç»Ÿè®¡:\n")
            f.write(f"  æ€»æ£€æµ‹åŒºåŸŸæ•°: {total_detections}\n")
            f.write(f"  æ€»å¤„ç†åŒºåŸŸæ•°: {total_processed}\n")
            f.write(f"  æ€»åˆ‡å‰²å›¾åƒæ•°: {total_cropped}\n\n")

            if failed > 0:
                f.write("å¤±è´¥æ–‡ä»¶:\n")
                for result in results:
                    if not result.get('success', False):
                        f.write(f"  - {result.get('image_path', 'æœªçŸ¥')}: ")
                        f.write(f"{result.get('error', 'æœªçŸ¥é”™è¯¯')}\n")

        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç®€åŒ–ç‰ˆå¤§è°±è¡¨å…‰å­¦éŸ³ä¹è¯†åˆ«ç³»ç»Ÿï¼ˆæ— SMTè¯†åˆ«ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¤„ç†å•å¼ å›¾åƒ
  python main.py --input sheet_music.jpg

  # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
  python main.py --batch scores_folder/

  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
  python main.py --input sheet.jpg --config my_config.yaml
        """
    )

    parser.add_argument('--input', type=str, help='è¾“å…¥å›¾åƒæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch', type=str, help='æ‰¹é‡å¤„ç†å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--config', type=str, default='config.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)')
    parser.add_argument('--model-dir', type=str, default='models',
                        help='æ¨¡å‹ç›®å½•è·¯å¾„ (é»˜è®¤: models)')

    args = parser.parse_args()

    if not args.input and not args.batch:
        parser.print_help()
        print("\nâŒ é”™è¯¯: è¯·æŒ‡å®š --input æˆ– --batch å‚æ•°")
        sys.exit(1)

    try:
        # åˆ›å»ºOMRç³»ç»Ÿå®ä¾‹
        omr_system = SimplifiedGrandStaffOMR(config_path=args.config)

        if args.input:
            # å•å¼ å›¾åƒå¤„ç†
            if not os.path.exists(args.input):
                print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {args.input}")
                sys.exit(1)

            result = omr_system.process_single_image(args.input)

            if result['success']:
                print(f"\nğŸ‰ å¤„ç†æˆåŠŸ!")
                print(f"   è¾“å‡ºç›®å½•: {omr_system.paths['base']}")
                print(f"   åˆ‡å‰²å›¾åƒ: {result.get('cropped_count', 0)}ä¸ª")
            else:
                print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('error')}")
                sys.exit(1)

        elif args.batch:
            # æ‰¹é‡å¤„ç†
            if not os.path.exists(args.batch):
                print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨ - {args.batch}")
                sys.exit(1)

            results = omr_system.process_batch(args.batch)

            successful = sum(1 for r in results if r.get('success', False))
            total = len(results)

            print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
            print(f"   æˆåŠŸ: {successful}/{total} ({successful / total * 100:.1f}%)")
            print(f"   è¾“å‡ºç›®å½•: {omr_system.paths['base']}")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()